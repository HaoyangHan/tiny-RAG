# TinyRAG v1.3.1 LLM API Testing Guide

**Date**: June 23, 2025  
**Version**: 1.3.1  
**Focus**: Real LLM Integration Testing

## üéØ **Testing Objectives**

This guide documents the systematic testing methodology for TinyRAG v1.3.1, focusing on real LLM integration testing with OpenAI GPT-4o-mini for document processing and metadata extraction.

## üèóÔ∏è **Architecture Overview**

### Current System Status
- **LLM Provider**: OpenAI GPT-4o-mini
- **Authentication**: JWT-based with User model
- **Document Processing**: PDF parsing with embeddings
- **Vector Store**: Qdrant
- **Cache**: Redis
- **Database**: MongoDB

### Services Health Status
| Service | Status | Port | Notes |
|---------|--------|------|-------|
| tinyrag-mongodb | ‚úÖ Healthy | 27017 | Primary database |
| tinyrag-redis | ‚úÖ Healthy | 6379 | Caching layer |
| tinyrag-qdrant | ‚úÖ Healthy | 6333-6334 | Vector database |
| tinyrag-api | ‚ö†Ô∏è Running | 8000 | Authentication issues |
| tinyrag-ui | ‚úÖ Created | 3000 | Frontend interface |
| tinyrag-worker | üîÑ Restarting | - | Background processing |

## üß™ **Testing Methodology**

### Phase 1: Infrastructure Testing

#### 1.1 Health Check Testing
```bash
# Input: Health endpoint request
curl -s http://localhost:8000/health | jq

# Expected Output:
{
  "status": "healthy",
  "version": "1.3.0",
  "services": {
    "auth": true,
    "llm_extractor": false,
    "enhanced_reranker": false,
    "document_service": true,
    "generation_service": true
  },
  "llm_provider": "openai",
  "llm_model": "gpt-4o-mini"
}
```

#### 1.2 Docker Services Testing
```bash
# Input: Service status check
docker-compose ps

# Expected Output: All core services (mongodb, redis, qdrant) healthy
```

### Phase 2: Authentication Testing

#### 2.1 User Registration
```bash
# Input: New user creation
curl -X POST "http://localhost:8000/auth/register" \
  -H "Content-Type: application/json" \
  -d '{
    "email": "test@example.com",
    "username": "testuser",
    "password": "TestPassword123!",
    "full_name": "Test User"
  }'

# Expected Output:
{
  "id": "USER_ID",
  "email": "test@example.com",
  "username": "testuser",
  "full_name": "Test User",
  "role": "user",
  "status": "active",
  "created_at": "2025-06-23T08:11:22.354000",
  "last_login": null
}
```

#### 2.2 User Login
```bash
# Input: User authentication
curl -X POST "http://localhost:8000/auth/login" \
  -H "Content-Type: application/json" \
  -d '{
    "identifier": "test@example.com",
    "password": "TestPassword123!"
  }'

# Expected Output:
{
  "access_token": "JWT_TOKEN_STRING",
  "token_type": "bearer",
  "expires_in": 1800
}
```

#### 2.3 Authenticated Request Testing
```bash
# Input: Protected endpoint access
curl -X GET "http://localhost:8000/auth/me" \
  -H "Authorization: Bearer JWT_TOKEN"

# Expected Output: User profile information
```

### Phase 3: Document Processing Testing

#### 3.1 Document Upload Testing
```bash
# Input: PDF document upload
curl -X POST "http://localhost:8000/documents/upload" \
  -H "Authorization: Bearer JWT_TOKEN" \
  -F "file=@/path/to/document.pdf"

# Expected Output:
{
  "id": "DOCUMENT_ID",
  "user_id": "USER_ID",
  "metadata": {
    "filename": "document.pdf",
    "content_type": "application/pdf",
    "size": 143360,
    "processed": true
  },
  "chunks": [...],
  "created_at": "2025-06-23T08:15:00.000000"
}
```

#### 3.2 Document Listing
```bash
# Input: User documents retrieval
curl -X GET "http://localhost:8000/documents" \
  -H "Authorization: Bearer JWT_TOKEN"

# Expected Output: Array of user documents
```

#### 3.3 Document Retrieval
```bash
# Input: Specific document access
curl -X GET "http://localhost:8000/documents/DOCUMENT_ID" \
  -H "Authorization: Bearer JWT_TOKEN"

# Expected Output: Full document with chunks and metadata
```

### Phase 4: LLM Integration Testing

#### 4.1 Document Metadata Extraction
- **Purpose**: Test LLM-powered metadata extraction from document content
- **Input**: Uploaded PDF document
- **Process**: DocumentProcessor ‚Üí OpenAI embeddings ‚Üí Metadata extraction
- **Expected Output**: Enhanced document metadata with LLM-extracted insights

#### 4.2 RAG Generation Testing
```bash
# Input: RAG query with document context
curl -X POST "http://localhost:8000/generate" \
  -H "Authorization: Bearer JWT_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What are the key skills mentioned?",
    "document_ids": ["DOCUMENT_ID"],
    "max_tokens": 1000,
    "temperature": 0.7
  }'

# Expected Output:
{
  "generation_id": "GENERATION_ID",
  "status": "processing",
  "message": "Generation started"
}
```

## üêõ **Current Issues & Debugging**

### Issue 1: Authentication Integration
**Status**: üî¥ **Active Issue**

**Problem**: Document upload returns "Invalid authentication credentials"

**Root Cause Analysis**:
1. **Architecture Conflict**: Mixed authentication systems
   - Old system: `dependencies.py` with simple JWT decode ‚Üí string user_id
   - New system: `main.py` with AuthService ‚Üí User object
2. **Integration Issue**: `dependencies.py` updated to use AuthService but service not properly injected

**Debugging Steps**:
```bash
# 1. Verify AuthService availability
curl -X GET "http://localhost:8000/auth/me" -H "Authorization: Bearer TOKEN"

# 2. Check if dependencies.py can access auth_service
# (Server logs show if service is None)

# 3. Test token validation manually
python -c "import jwt; print(jwt.decode('TOKEN', verify=False))"
```

**Attempted Solutions**:
- ‚úÖ Updated `dependencies.py` to use proper AuthService
- ‚úÖ Updated `routes/documents.py` to handle User objects
- ‚úÖ Added auth service injection in `main.py`
- ‚ùå Still failing authentication

### Issue 2: Document Processing Architecture
**Status**: üü° **Monitoring**

**Current Approach**: 
- Using `DocumentProcessor` with OpenAI embeddings
- Processing through `routes/documents.py`
- No longer using conflicting `DocumentService.upload_and_process()`

## üìä **Test Results Summary**

| Test Category | Status | Success Rate | Notes |
|---------------|--------|--------------|-------|
| Health Check | ‚úÖ Pass | 100% | All endpoints responding |
| User Registration | ‚úÖ Pass | 100% | Proper validation working |
| User Login | ‚úÖ Pass | 100% | JWT generation working |
| Document Upload | ‚ùå Fail | 0% | Authentication integration issue |
| Document List | ‚ùå Fail | 0% | Dependent on upload |
| LLM Integration | ‚è∏Ô∏è Pending | - | Blocked by upload issue |

## üîÑ **Next Steps**

### Immediate Actions
1. **Fix Authentication Integration**
   - Debug AuthService injection
   - Verify token validation flow
   - Test auth dependency chain

2. **Document Upload Resolution**
   - Complete authentication fix
   - Test with real PDF file
   - Verify OpenAI integration

3. **LLM Testing**
   - Document metadata extraction
   - RAG generation testing
   - Performance benchmarking

### Testing Environment Requirements
- **Docker**: Clean environment with all services healthy
- **Test Files**: PDF documents for upload testing
- **Credentials**: Valid test user accounts
- **Environment Variables**: OpenAI API key configured

## üìù **Test Execution Log**

### Session: June 23, 2025
- **09:00**: Docker environment cleaned and rebuilt
- **09:15**: All core services healthy
- **09:30**: Authentication endpoints tested successfully
- **09:45**: Document upload authentication issue identified
- **10:00**: Architecture analysis completed
- **10:15**: Documentation created

### Test User Credentials
- **Email**: tester4@example.com
- **Username**: tester4
- **Password**: TestPassword123!
- **User ID**: 68590c2a09baf9c29f0a620f

## üéØ **Success Criteria**

### V1.3.1 LLM Testing Goals
- [ ] Document upload with LLM metadata extraction
- [ ] RAG generation with real OpenAI responses
- [ ] Performance metrics for LLM operations
- [ ] Error handling for LLM failures
- [ ] Integration testing with all components

### Quality Metrics
- **Response Time**: < 5s for document upload
- **LLM Latency**: < 10s for metadata extraction
- **Accuracy**: Manual validation of extracted metadata
- **Reliability**: 95% success rate for standard operations 